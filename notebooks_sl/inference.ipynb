{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3e01c35",
      "metadata": {},
      "source": [
        "### Tinker phishing classifier (clean)\n",
        "\n",
        "This notebook runs **inference** with your fine-tuned Tinker sampler and produces a final DataFrame that includes:\n",
        "- `category`: the model prediction (`GENUINE`/`PHISHING`/`ASSIGN_TO_AGENT`)\n",
        "- `agent_notes_pred`: the model-provided agent notes extracted from the assistant text (e.g. `agent_notes: ...`)\n",
        "\n",
        "**Prereqs**\n",
        "- `TINKER_API_KEY` is set (this notebook loads `.env` if present).\n",
        "- You have a completed run log with `checkpoints.jsonl` at `LOG_PATH` (default: `/tmp/tinker-examples/sl_ar_phishing`).\n",
        "\n",
        "**Outputs**\n",
        "- `df_tinker`: per-ticket predictions + `agent_notes_pred`\n",
        "- `df_phishing_messages_tinker`: your evaluation DataFrame with predictions merged in\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3a45398e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ext-elias.melas/Documents/Gitcode/ar_finetune/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Imports + environment\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "from enum import StrEnum\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, Field\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3ae0a57b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    2241\n",
              "0    2231\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    560\n",
              "0    558\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lora_train = pd.read_parquet(\"../data/finetuning/lora_train_emails.parquet\")\n",
        "lora_test = pd.read_parquet(\"../data/finetuning/lora_test_emails.parquet\")\n",
        "\n",
        "display(lora_train[\"label\"].value_counts(dropna=False))\n",
        "display(lora_test[\"label\"].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb2885b5",
      "metadata": {},
      "source": [
        "### 1) Benchmark (Azure OpenAI, structured output)\n",
        "\n",
        "This section runs the baseline classifier using Azure OpenAI with structured outputs (`VerificationClassification`).\n",
        "\n",
        "- Requires `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_VERSION`, `AZURE_OPENAI_DEPLOYMENT`\n",
        "- Produces `df_gpt` and `df_phishing_messages_gpt`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "314896a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI client ready\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  4.34it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "is_spam_pred\n",
              "False    3\n",
              "True     2\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# GPT-5.2 benchmark (spam) — parse `is_spam: 1/0`\n",
        "# Uses the same lightweight label format as your fine-tuned Tinker model.\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Make env loading robust even if the notebook's CWD isn't repo root.\n",
        "load_dotenv(dotenv_path=Path(\"../.env\"), override=False)\n",
        "\n",
        "import os\n",
        "import re\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "from openai import AsyncAzureOpenAI, AsyncOpenAI\n",
        "\n",
        "AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
        "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_OPENAI_API_VERSION = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "missing = [\n",
        "    k\n",
        "    for k, v in {\n",
        "        \"AZURE_OPENAI_API_KEY\": AZURE_OPENAI_API_KEY,\n",
        "        \"AZURE_OPENAI_ENDPOINT\": AZURE_OPENAI_ENDPOINT,\n",
        "        \"AZURE_OPENAI_API_VERSION\": AZURE_OPENAI_API_VERSION,\n",
        "        \"OPENAI_API_KEY\": OPENAI_API_KEY,\n",
        "    }.items()\n",
        "    if not v\n",
        "]\n",
        "if missing:\n",
        "    raise RuntimeError(\n",
        "        \"Missing env vars: \"\n",
        "        + \", \".join(missing)\n",
        "        + \"\\nSet them in your .env (or environment) and re-run this cell.\"\n",
        "    )\n",
        "\n",
        "# Azure client kept around (handy for other experiments), but this benchmark uses OPENAI_API_KEY.\n",
        "azure_client = AsyncAzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=AZURE_OPENAI_API_VERSION,\n",
        ")\n",
        "oai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "print(\"OpenAI client ready\")\n",
        "\n",
        "\n",
        "system_prompt = Path(\"../data/verification/system_prompt_spam.md\").read_text()\n",
        "\n",
        "def _build_email_user_prompt(*, subject: str, body: str) -> str:\n",
        "    return f\"\"\"\n",
        "Email subject:\n",
        "---------------------------------------------------\n",
        "\\n{subject}\\n\\n\n",
        "---------------------------------------------------\n",
        "Email body:\n",
        "---------------------------------------------------\n",
        "\\n{body}\\n\\n\n",
        "---------------------------------------------------\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def _parse_is_spam(text: str) -> bool | None:\n",
        "    m = re.search(r\"\\bis_spam\\s*:\\s*(-1|0|1|true|false)\\b\", text, flags=re.IGNORECASE)\n",
        "    if m is None:\n",
        "        return None\n",
        "\n",
        "    v = m.group(1).lower()\n",
        "    if v == \"-1\":\n",
        "        return None\n",
        "\n",
        "    return v in (\"1\", \"true\")\n",
        "\n",
        "\n",
        "async def classify_spam_gpt52(\n",
        "    *,\n",
        "    subject: str,\n",
        "    body: str,\n",
        "    system_prompt: str = system_prompt,\n",
        ") -> tuple[bool | None, str]:\n",
        "    user_prompt = _build_email_user_prompt(subject=subject, body=body)\n",
        "\n",
        "    response = await oai_client.responses.create(\n",
        "        model=\"gpt-5.2-2025-12-11\",\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    text = (getattr(response, \"output_text\", \"\") or \"\").strip()\n",
        "    return _parse_is_spam(text), text\n",
        "\n",
        "\n",
        "async def process_all_emails_gpt52(\n",
        "    df_messages: pd.DataFrame,\n",
        "    *,\n",
        "    concurrency: int = 50,\n",
        "    max_rows: int | None = None,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Run GPT-5.2 spam classification over a dataframe of emails.\"\"\"\n",
        "\n",
        "    sem = asyncio.Semaphore(concurrency)\n",
        "    rows = list(df_messages.iterrows())\n",
        "    if max_rows is not None:\n",
        "        rows = rows[:max_rows]\n",
        "\n",
        "    async def process_single(row_idx: Any, row: pd.Series) -> Dict[str, Any]:\n",
        "        async with sem:\n",
        "            try:\n",
        "                is_spam_pred, raw_text = await classify_spam_gpt52(\n",
        "                    subject=str(row.get(\"subject\", \"\")),\n",
        "                    body=str(row.get(\"body\", \"\")),\n",
        "                )\n",
        "                return {\n",
        "                    \"ticket_id\": row.get(\"ticket_id\", row_idx),\n",
        "                    \"is_spam_pred\": is_spam_pred,\n",
        "                    \"raw\": raw_text,\n",
        "                    \"success\": True,\n",
        "                    \"error\": None,\n",
        "                }\n",
        "            except Exception as e:\n",
        "                return {\n",
        "                    \"ticket_id\": row.get(\"ticket_id\", row_idx),\n",
        "                    \"is_spam_pred\": None,\n",
        "                    \"raw\": None,\n",
        "                    \"success\": False,\n",
        "                    \"error\": repr(e),\n",
        "                }\n",
        "\n",
        "    tasks = [asyncio.create_task(process_single(row_idx, row)) for row_idx, row in rows]\n",
        "\n",
        "    results: list[Dict[str, Any]] = []\n",
        "    for fut in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
        "        results.append(await fut)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "gpt_results = await process_all_emails_gpt52(lora_test.iloc[:5], concurrency=50, max_rows=None)\n",
        "df_gpt = pd.DataFrame(gpt_results)\n",
        "\n",
        "# If you want to persist results:\n",
        "# df_gpt.to_parquet(\"../data/verification/gpt52_results_spam.parquet\")\n",
        "# df_gpt = pd.read_parquet(\"../data/verification/gpt52_results_spam.parquet\")\n",
        "\n",
        "# Merge predictions back into the evaluation dataframe.\n",
        "if \"ticket_id\" in lora_test.columns:\n",
        "    df_eval = lora_test\n",
        "else:\n",
        "    df_eval = lora_test.reset_index().rename(columns={\"index\": \"ticket_id\"})\n",
        "\n",
        "df_spam_messages_gpt = df_eval.merge(\n",
        "    df_gpt[[\"ticket_id\", \"is_spam_pred\", \"raw\", \"success\", \"error\"]],\n",
        "    on=\"ticket_id\",\n",
        "    how=\"inner\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "display(df_spam_messages_gpt[\"is_spam_pred\"].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ce91fd92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT accuracy: 1.0\n",
            "Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
            "Confusion Matrix: [[3 0]\n",
            " [0 2]]\n"
          ]
        }
      ],
      "source": [
        "# Quick metrics (optional)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Ground truth for the email dataset is `label` (bool/int).\n",
        "# Predictions come from GPT as `is_spam_pred` (bool | None).\n",
        "mask = df_spam_messages_gpt[\"is_spam_pred\"].notna()\n",
        "\n",
        "y_true = df_spam_messages_gpt.loc[mask, \"label\"].astype(bool)\n",
        "y_pred = df_spam_messages_gpt.loc[mask, \"is_spam_pred\"].astype(bool)\n",
        "\n",
        "print(\"GPT accuracy:\", accuracy_score(y_true, y_pred))\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "print(f\"Confusion Matrix: {cm}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a4847c",
      "metadata": {},
      "source": [
        "### 3) Create a SamplingClient for the fine-tuned checkpoint\n",
        "\n",
        "We load the last sampler checkpoint from `LOG_PATH/checkpoints.jsonl` and create a `sampling_client` for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tinker-cookbook repo: /Users/ext-elias.melas/Documents/Gitcode/tinker-cookbook\n"
          ]
        }
      ],
      "source": [
        "# Make `tinker_cookbook` importable without installing it.\n",
        "\n",
        "import sys\n",
        "\n",
        "def find_tinker_cookbook_repo(start: Path) -> Path:\n",
        "    candidates: list[Path] = []\n",
        "    for p in [start, *start.parents]:\n",
        "        candidates.append(p / \"tinker-cookbook\")\n",
        "        candidates.append(p)\n",
        "    for repo in candidates:\n",
        "        if (repo / \"tinker_cookbook\" / \"__init__.py\").exists():\n",
        "            return repo\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find the tinker-cookbook repo (missing tinker_cookbook/__init__.py).\"\n",
        "    )\n",
        "\n",
        "TINKER_COOKBOOK_REPO = find_tinker_cookbook_repo(Path.cwd())\n",
        "if str(TINKER_COOKBOOK_REPO) not in sys.path:\n",
        "    sys.path.insert(0, str(TINKER_COOKxBOOK_REPO))\n",
        "\n",
        "import tinker_cookbook  # noqa: F401\n",
        "\n",
        "print(\"tinker-cookbook repo:\", TINKER_COOKBOOK_REPO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last sampler checkpoint: tinker://ab71f6d1-f9b1-5f68-b387-59bb7b34c066:train:0/sampler_weights/final\n",
            "Sampling client ready\n"
          ]
        }
      ],
      "source": [
        "# Choose where inference runs:\n",
        "# - True: run LOCALLY using your downloaded adapter at ../adapters/lora_adapter\n",
        "# - False: run REMOTELY on Tinker using the sampler_path from LOG_PATH/checkpoints.jsonl\n",
        "USE_LOCAL_ADAPTER = False\n",
        "\n",
        "# --- Local adapter inference (Transformers + PEFT) ---\n",
        "if USE_LOCAL_ADAPTER:\n",
        "    ####### TODO (WIP) ########\n",
        "    import torch\n",
        "    from peft import PeftModel\n",
        "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "    BASE_MODEL_DIR = Path(\"../models/llama-3.1-8b\")\n",
        "    ADAPTER_DIR = Path(\"../adapters/lora_adapter_spam\")\n",
        "\n",
        "    if not BASE_MODEL_DIR.exists():\n",
        "        raise FileNotFoundError(f\"Base model not found: {BASE_MODEL_DIR}\")\n",
        "    if not ADAPTER_DIR.exists():\n",
        "        raise FileNotFoundError(f\"Adapter not found: {ADAPTER_DIR}\")\n",
        "\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    dtype = torch.float16 if device in {\"cuda\", \"mps\"} else torch.float32\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_DIR)\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_DIR, torch_dtype=dtype)\n",
        "    base_model.to(device)\n",
        "\n",
        "    model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
        "    model.eval()\n",
        "\n",
        "    def _render_role_colon(messages: list[dict[str, str]]) -> str:\n",
        "        # Match the role_colon style used during training.\n",
        "        parts: list[str] = []\n",
        "        for m in messages:\n",
        "            role = (m.get(\"role\") or \"\").strip().lower()\n",
        "            content = (m.get(\"content\") or \"\").strip()\n",
        "            if role == \"system\":\n",
        "                parts.append(f\"System: {content}\")\n",
        "            elif role == \"user\":\n",
        "                parts.append(f\"User: {content}\")\n",
        "            elif role == \"assistant\":\n",
        "                parts.append(f\"Assistant: {content}\")\n",
        "            else:\n",
        "                parts.append(f\"{role.title()}: {content}\")\n",
        "        # Add generation cue\n",
        "        return \"\\n\\n\".join(parts) + \"\\n\\nAssistant:\"\n",
        "\n",
        "    async def tinker_completer(messages: list[dict[str, str]]) -> dict[str, str]:\n",
        "        # Keep the same interface as TinkerMessageCompleter: returns {role, content}.\n",
        "        prompt = _render_role_colon(messages)\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            out = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=64,\n",
        "                do_sample=False,\n",
        "                temperature=0.0,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "        gen = out[0][inputs[\"input_ids\"].shape[-1] :]\n",
        "        text = tokenizer.decode(gen, skip_special_tokens=True).strip()\n",
        "\n",
        "        # Trim if the model starts a new turn\n",
        "        text = text.split(\"\\n\\nUser:\", 1)[0].strip()\n",
        "\n",
        "        return {\"role\": \"assistant\", \"content\": text}\n",
        "\n",
        "    print(\"Local inference enabled\")\n",
        "    print(\"Device:\", device)\n",
        "    print(\"Base model:\", BASE_MODEL_DIR)\n",
        "    print(\"Adapter:\", ADAPTER_DIR)\n",
        "\n",
        "# --- Remote Tinker inference (SamplingClient) ---\n",
        "else:\n",
        "    import tinker\n",
        "    from tinker_cookbook.checkpoint_utils import get_last_checkpoint\n",
        "\n",
        "    # Update this if your run logs are elsewhere.\n",
        "    LOG_PATH = Path(\"/tmp/tinker-examples/sl_ar_phishing_spam\")\n",
        "\n",
        "    service_client = tinker.ServiceClient()\n",
        "\n",
        "    ckpt_sampler = get_last_checkpoint(str(LOG_PATH), required_key=\"sampler_path\")\n",
        "    print(\"Last sampler checkpoint:\", ckpt_sampler.get(\"sampler_path\") if ckpt_sampler else None)\n",
        "\n",
        "    if not ckpt_sampler:\n",
        "        raise RuntimeError(\n",
        "            \"No sampler checkpoint found. Ensure training ran and wrote checkpoints.jsonl under LOG_PATH.\"\n",
        "        )\n",
        "\n",
        "    sampling_client = service_client.create_sampling_client(model_path=ckpt_sampler[\"sampler_path\"])\n",
        "    print(\"Sampling client ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Build the Tinker message completer\n",
        "\n",
        " In the Tinker Cookbook, policies are implemented as Completers. Completers are abstractions that represent models or policies that can be sampled from, providing different levels of structure depending on your use case.\n",
        "\n",
        "The Tinker Cookbook provides two main types of completers, each designed for different use cases:\n",
        "- TokenCompleter: Operates on tokens and is used by RL algorithms\n",
        "- MessageCompleter: Operates on messages and needs to be used with a renderer\n",
        "The choice between these depends on whether you're working at the token level for RL training or at the message level for interacting with and evaluating the model.\n",
        "\n",
        "We build a renderer/tokenizer matching the base model family and then create a `TinkerMessageCompleter` that returns assistant messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c2229a51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remote Tinker inference enabled\n",
            "Model: meta-llama/Llama-3.1-8B\n",
            "Renderer: role_colon\n",
            "Stop sequences: ['\\n\\nUser:']\n"
          ]
        }
      ],
      "source": [
        "# Build the message completer\n",
        "# - If USE_LOCAL_ADAPTER=True, `tinker_completer` was defined in the previous cell (local Transformers+PEFT).\n",
        "# - Otherwise, create a remote TinkerMessageCompleter.\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
        "\n",
        "if not USE_LOCAL_ADAPTER:\n",
        "    from tinker_cookbook import model_info\n",
        "    from tinker_cookbook.completers import TinkerMessageCompleter\n",
        "    from tinker_cookbook import renderers as cookbook_renderers\n",
        "    from tinker_cookbook.tokenizer_utils import get_tokenizer\n",
        "\n",
        "    RENDERER_NAME = model_info.get_recommended_renderer_name(MODEL_NAME)\n",
        "\n",
        "    tok = get_tokenizer(MODEL_NAME)\n",
        "    renderer = cookbook_renderers.get_renderer(RENDERER_NAME, tok)\n",
        "\n",
        "    tinker_completer = TinkerMessageCompleter(\n",
        "        sampling_client=sampling_client,\n",
        "        renderer=renderer,\n",
        "        max_tokens=64,\n",
        "    )\n",
        "\n",
        "    print(\"Remote Tinker inference enabled\")\n",
        "    print(\"Model:\", MODEL_NAME)\n",
        "    print(\"Renderer:\", RENDERER_NAME)\n",
        "    print(\"Stop sequences:\", renderer.get_stop_sequences())\n",
        "else:\n",
        "    print(\"Local adapter inference enabled\")\n",
        "    print(\"Model:\", MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Classify with Tinker adapter\n",
        "\n",
        "Your fine-tuned model returns assistant text like:\n",
        "- `is_phishing: True, agent_notes: ...`\n",
        "\n",
        "We parse both fields and store the notes as `agent_notes_pred`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "95391782",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SpamClassification(BaseModel):\n",
        "    is_spam: bool | None = Field(...)\n",
        "\n",
        "\n",
        "# Spam system prompt for the email classifier fine-tune.\n",
        "system_prompt = Path(\"../data/verification/system_prompt_spam.md\").read_text()\n",
        "\n",
        "\n",
        "def _build_user_prompt(*, subject: str, body: str) -> str:\n",
        "    return f\"\"\"\n",
        "Email subject:\n",
        "---------------------------------------------------\n",
        "\\n{subject}\\n\\n\n",
        "---------------------------------------------------\n",
        "Email body:\n",
        "---------------------------------------------------\n",
        "\\n{body}\\n\\n\n",
        "---------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "async def classify_phishing_tinker(\n",
        "    *,\n",
        "    subject: str,\n",
        "    body: str,\n",
        "    system_prompt: str = system_prompt,\n",
        ") -> tuple[VerificationClassification, str | None]:\n",
        "    user_prompt = _build_user_prompt(subject=subject, body=body)\n",
        "\n",
        "    convo = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    assistant_msg = await tinker_completer(convo)\n",
        "    print(assistant_msg)\n",
        "    text = str(assistant_msg.get(\"content\", \"\")).strip()\n",
        "\n",
        "    # Expected assistant output (common formats):\n",
        "    # - \"is_spam: 1\"\n",
        "    # - \"is_spam: 0\"\n",
        "    # - \"is_spam: True\" / \"is_spam: False\"\n",
        "    m = re.search(r\"\\bis_spam\\s*:\\s*(1|0|true|false)\\b\", text, flags=re.IGNORECASE)\n",
        "    if m is None:\n",
        "        return SpamClassification(is_spam=False), None\n",
        "\n",
        "    v = m.group(1).lower()\n",
        "    is_spam = v in (\"1\", \"true\")\n",
        "\n",
        "    # NOTE: We reuse the original PHISHING/GENUINE categories.\n",
        "    # Here, PHISHING corresponds to the positive class (spam).\n",
        "    is_spam = SpamClassification(is_spam=is_spam)\n",
        "\n",
        "    notes_match = re.search(r\"\\bagent_notes\\s*:\\s*(.*)$\", text, flags=re.IGNORECASE | re.DOTALL)\n",
        "    agent_notes_pred = notes_match.group(1).strip() if notes_match else None\n",
        "    if agent_notes_pred == \"\":\n",
        "        agent_notes_pred = None\n",
        "\n",
        "    return is_spam, agent_notes_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "4a8b4029",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:01<00:02,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'role': 'assistant', 'content': 'is_spam: 1'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 1'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 1'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 1'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n",
            "{'role': 'assistant', 'content': 'is_spam: 0'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticket_id</th>\n",
              "      <th>is_spam_pred</th>\n",
              "      <th>success</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1451</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>808</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2659</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3829</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5550</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ticket_id is_spam_pred  success error\n",
              "0       1451         True     True  None\n",
              "1        808        False     True  None\n",
              "2       2659        False     True  None\n",
              "3       3829        False     True  None\n",
              "4       5550        False     True  None"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async def process_all_messages_phishing_tinker(\n",
        "    df_messages: pd.DataFrame,\n",
        "    *,\n",
        "    concurrency: int = 16,\n",
        "    max_rows: int | None = None,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Run Tinker inference over a dataframe of rows.\"\"\"\n",
        "\n",
        "    sem = asyncio.Semaphore(concurrency)\n",
        "    rows = list(df_messages.iterrows())\n",
        "    if max_rows is not None:\n",
        "        rows = rows[:max_rows]\n",
        "\n",
        "    async def process_single(row_idx: Any, row: pd.Series) -> Dict[str, Any]:\n",
        "        async with sem:\n",
        "            pred, agent_notes_pred = await classify_phishing_tinker(\n",
        "                subject=str(row.get(\"subject\", \"\")),\n",
        "                body=str(row.get(\"body\", \"\")),\n",
        "            )\n",
        "\n",
        "            # Store category as a plain string for easier pandas usage.\n",
        "            is_spam = pred.is_spam.value if hasattr(pred.is_spam, \"value\") else str(pred.is_spam)\n",
        "\n",
        "            # Some datasets don't have ticket_id; fall back to the row index.\n",
        "            ticket_id = row.get(\"ticket_id\", row_idx)\n",
        "\n",
        "            return {\n",
        "                \"ticket_id\": ticket_id,\n",
        "                \"is_spam_pred\": is_spam,\n",
        "                \"success\": True,\n",
        "                \"error\": None,\n",
        "            }\n",
        "\n",
        "    tasks = [asyncio.create_task(process_single(row_idx, row)) for row_idx, row in rows]\n",
        "\n",
        "    results: list[Dict[str, Any]] = []\n",
        "    for fut in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
        "        results.append(await fut)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "tinker_results = await process_all_messages_phishing_tinker(lora_test.iloc[:10], max_rows=None)\n",
        "df_tinker = pd.DataFrame(tinker_results)\n",
        "# df_tinker.to_parquet(\"../data/verification/tinker_results_spam.parquet\")\n",
        "# df_tinker = pd.read_parquet(\"../data/verification/tinker_results_spam.parquet\")\n",
        "df_tinker.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "51a703dd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is_spam_pred\n",
              "False    6\n",
              "True     4\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticket_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "      <th>is_spam_pred</th>\n",
              "      <th>pred_bool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5438</td>\n",
              "      <td>cera conference call and web presentation : wi...</td>\n",
              "      <td>scenarios . . . - cera conference call\\r\\ncera...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>808</td>\n",
              "      <td>revision # 1 - hpl nom for july 25 , 2000</td>\n",
              "      <td>( see attached file : hplo 725 . xls )\\r\\n- hp...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4497</td>\n",
              "      <td>you have won congratulation ! ! lucky winner !...</td>\n",
              "      <td>dayzer lottery national promotion .\\r\\npostbus...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2662</td>\n",
              "      <td>ambllen , alprazzolam , \\\\ / aluum , \\\\ / llgr...</td>\n",
              "      <td>terrible showed gotten teacher among . speech ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3829</td>\n",
              "      <td>hr generalist for your group</td>\n",
              "      <td>norma villarreal is the hr generalist for all ...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1451</td>\n",
              "      <td>appointment on sunday at 18 - 00</td>\n",
              "      <td>remove\\r\\nperch brunoguffaw handicapper conjug...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2083</td>\n",
              "      <td>fw : epmi / aep / allegheny ring transaction c...</td>\n",
              "      <td>below please find proposed confirms for the pr...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5550</td>\n",
              "      <td>february 7 th update</td>\n",
              "      <td>jeff / michelle / ken ,\\r\\nhere is the daily u...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2659</td>\n",
              "      <td>asking for advice regarding summer associate p...</td>\n",
              "      <td>shirley ,\\r\\nplease , set up a phone interview...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2806</td>\n",
              "      <td>promote your business</td>\n",
              "      <td>the power of email marketing\\r\\nemail marketin...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ticket_id                                            subject  \\\n",
              "0       5438  cera conference call and web presentation : wi...   \n",
              "1        808          revision # 1 - hpl nom for july 25 , 2000   \n",
              "2       4497  you have won congratulation ! ! lucky winner !...   \n",
              "3       2662  ambllen , alprazzolam , \\\\ / aluum , \\\\ / llgr...   \n",
              "4       3829                       hr generalist for your group   \n",
              "5       1451                   appointment on sunday at 18 - 00   \n",
              "6       2083  fw : epmi / aep / allegheny ring transaction c...   \n",
              "7       5550                               february 7 th update   \n",
              "8       2659  asking for advice regarding summer associate p...   \n",
              "9       2806                              promote your business   \n",
              "\n",
              "                                                body  label is_spam_pred  \\\n",
              "0  scenarios . . . - cera conference call\\r\\ncera...      0        False   \n",
              "1  ( see attached file : hplo 725 . xls )\\r\\n- hp...      0        False   \n",
              "2  dayzer lottery national promotion .\\r\\npostbus...      1         True   \n",
              "3  terrible showed gotten teacher among . speech ...      1         True   \n",
              "4  norma villarreal is the hr generalist for all ...      0        False   \n",
              "5  remove\\r\\nperch brunoguffaw handicapper conjug...      1         True   \n",
              "6  below please find proposed confirms for the pr...      0        False   \n",
              "7  jeff / michelle / ken ,\\r\\nhere is the daily u...      0        False   \n",
              "8  shirley ,\\r\\nplease , set up a phone interview...      0        False   \n",
              "9  the power of email marketing\\r\\nemail marketin...      1         True   \n",
              "\n",
              "   pred_bool  \n",
              "0      False  \n",
              "1      False  \n",
              "2       True  \n",
              "3       True  \n",
              "4      False  \n",
              "5       True  \n",
              "6      False  \n",
              "7      False  \n",
              "8      False  \n",
              "9       True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Merge predictions back into the evaluation dataframe.\n",
        "# Some datasets (like Enron) don't have a ticket_id column.\n",
        "if \"ticket_id\" in lora_test.columns:\n",
        "    df_eval = lora_test\n",
        "else:\n",
        "    df_eval = lora_test.reset_index().rename(columns={\"index\": \"ticket_id\"})\n",
        "\n",
        "df_phishing_messages_tinker = df_eval.merge(\n",
        "    df_tinker[[\"ticket_id\",\"is_spam_pred\"]],\n",
        "    on=\"ticket_id\",\n",
        "    how=\"inner\",\n",
        ")\n",
        "df_phishing_messages_tinker['pred_bool'] = df_phishing_messages_tinker['is_spam_pred'].map(lambda x: True if x == \"True\" else False)\n",
        "\n",
        "display(\n",
        "    df_phishing_messages_tinker[\"is_spam_pred\"].value_counts(dropna=False),\n",
        "    df_phishing_messages_tinker\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f4f617",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_phishing_messages_tinker.dropna(subset=['category'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "37b63703",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuned Llama 3.1-8B accuracy: 1.0\n",
            "Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
            "Confusion Matrix: [[6 0]\n",
            " [0 4]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Ground truth for the email dataset is `label` (bool/int).\n",
        "y_true = (\n",
        "    df_phishing_messages_tinker[\"label\"]\n",
        ").astype(bool)\n",
        "\n",
        "y_pred = (\n",
        "    df_phishing_messages_tinker[\"pred_bool\"]\n",
        ")\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "\n",
        "print(\"Fine-tuned Llama 3.1-8B accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "print(f\"Confusion Matrix: {cm}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
